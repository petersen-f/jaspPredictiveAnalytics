[{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/background.html","id":"general-documentation","dir":"Articles","previous_headings":"","what":"General Documentation","title":"Background","text":"document provides exact information info button  JASP completeness searchability.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/background.html","id":"probalistic-prediction","dir":"Articles","previous_headings":"","what":"Probalistic Prediction","title":"Background","text":"work progress","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/background.html","id":"models","dir":"Articles","previous_headings":"","what":"Models","title":"Background","text":"work progress","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/background.html","id":"ensemble-bayesian-model-averaging","dir":"Articles","previous_headings":"","what":"Ensemble Bayesian Model Averaging","title":"Background","text":"work progress","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"predictive-analytics","dir":"Articles","previous_headings":"","what":"Predictive Analytics","title":"Background","text":"module allows user perform probalistic time series forecasting.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"assumptions","dir":"Articles","previous_headings":"Predictive Analytics","what":"Assumptions","title":"Background","text":"missing covariates factors","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"assignment-box","dir":"Articles","previous_headings":"Predictive Analytics > Input","what":"Assignment Box","title":"Background","text":"Dependent Variable: Time series variable predicted (needed) Time: Time variable corresponds time stamp observation. Can following formats: [‘YYYY-MM-DD’, ‘YYYY/MM/DD’, ‘YYYY-MM-DD HH:MM:SS’, ‘YYYY/MM/DD HH:MM:SS’] (needed)“) Covariates: Covariates used prediction model Factors: Factors used prediction model Training Indicator: Logical variable (0 1) indicating cases used training verifying models (= 1) cases predicted (= 0). variable necessary making predictions covariates factors supplied","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"error-bound-selection-method","dir":"Articles","previous_headings":"Predictive Analytics > Input > Time Series Descriptive","what":"Error Bound Selection Method","title":"Background","text":"Data Based: Bounds automatically selected based mean many standard deviations data away mean. σ threshold: Indicated number standard deviations used calculate bound. example, set 2, data 2 standard deviations away flagged --control Trimmed mean: mean determines bounds calculated discarding upper lower xx quantile sample. Custom period: mean calculated based indicated period. Useful specific period available process known control. Manual bounds: Bounds manually set Upper/Lower bound: Determines separately upper lower bound .","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"control-plots","dir":"Articles","previous_headings":"Predictive Analytics > Input > Time Series Descriptive","what":"Control Plots","title":"Background","text":"Spread points equally: Ignores timestamp data point plots sequentially distance . Points/Line/: Displays data points either points, line time. Y-Axis Limits: Plot either shows data available focuses control bounds might cut outliers. Enable grid: Shows grid control chart Custom plot focus: Adds separate plot shows data indicated time period. --bound percent threshold: Sets percent data needs --bound trigger warning.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"tables","dir":"Articles","previous_headings":"Predictive Analytics > Input > Diagnostics","what":"Tables","title":"Background","text":"Summary statistics: Table shows summary statistics time series variable aggregated whether data control. Transpose table: Transposes table data points shown columns variables shown rows. Custom table focus: shows outliers indicated time period.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"plots","dir":"Articles","previous_headings":"Predictive Analytics > Input > Diagnostics","what":"Plots","title":"Background","text":"Lags: Maximum number lags shown. Partial autocorrelation function: Additionally shows partial autocorrelation function plot.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"feature-engineering","dir":"Articles","previous_headings":"Predictive Analytics > Input","what":"Feature Engineering","title":"Background","text":"Options create automatic time series features might improve prediction accuracy models. - Nr. lags: Number lags used create lagged time series variables features. --sample predictions, previous predictions used create lagged variables prevent data leakage. - Automatic time-based features: Creates multiple features based time variable. example, create column indicates specific month (1-12), day (1-31), hour (1-24), minute (1-60)etc. time stamp. useful models don’t model seasonality automatically. - Remove zero-variance variables: Removes variables zero variance. - Remove variables stronger correlated : Removes variables strongly correlated . threshold set user.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"evaluation-plan","dir":"Articles","previous_headings":"Predictive Analytics > Input > Forecast Evaluation","what":"Evaluation Plan","title":"Background","text":"section allows evaluating selected models performs best terms predictive performance available data. helpful determining model used future predictions. goal evaluate predictive performance unseen future observation, normal cross validation randomly selects training test data appropriate. Instead, data split way training data always test data. example model trained first 100 observations predictive performance evaluated next 10 observations. Afterwards data shifted ahead certain amount observations model process repeated multiple times. called rolling window cross validation. predictive performance evaluated deterministic probabilistic metrics averaged across slices. - Training window: Indicates number observations used training model. - Prediction window: Indicates number observations used assess predictive performance model. - Select slices : Indicates whether slices selected start end data. - Maximum nr. slices: Indicates maximum number slices used evaluation. actual number slices might lower data long enough. - Cumulative training: Indicates training window grows cumulative slice . Increases time needed evaluation models trained longer longer time periods. - Show evaluation plan: Plots evaluation plan used model evaluation. - Spread points equally: Ignores timestamp data point plots sequentially distance . - Max slices shown: Maximum number slices shown plot. Actual number can higher.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"model-choice","dir":"Articles","previous_headings":"Predictive Analytics > Input > Forecast Evaluation","what":"Model Choice","title":"Background","text":"Select models used prediction evaluated. model family indicated first part model name hyphen “-” indicates model specification afterwards. example model “linear regression - regression + lag” normal linear Bayesian regression model uses covariates factors input well lagged variables created “Feature Engineering” section. specific model families model specifications explained .","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"model-families","dir":"Articles","previous_headings":"","what":"Background","title":"Background","text":"linear regression: Basic Bayesian linear regression model uses spike slab prior variable selection. bsts: Bayesian structural time series model decomposes time series different hidden components. Models hidden state either linear trend auto-regressive process. Can also include regressors via spike slab regression additional component. prophet: Bayesian time series model automatically models appropriate seasonality via fourier orders, trend change points. Can also include regressors additional component. xgboost: Gradient boosting model uses tree-based model predict time series variable. automatically model seasonality. probalisitic. bart: Bayesian additive regression tree model similar “sum--tree” models regularises impact tree via prior. automatically model seasonality.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"model-specifications","dir":"Articles","previous_headings":"","what":"Background","title":"Background","text":"time: uses time variable input. Useful baseline model compare complex models. regression: uses covariates factors input well automatic time-based features enabled lag: Additionally uses lagged time series variables input.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"evaluation-metrics","dir":"Articles","previous_headings":"Predictive Analytics > Input > Forecast Evaluation","what":"Evaluation Metrics","title":"Background","text":"probabilistic metrics available models probabilistic assess prediction performance based whole predictive density taking account uncertainty around forecast. deterministic metrics available models take account mean forecast. metrics explained .","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"probabilistic-metrics","dir":"Articles","previous_headings":"","what":"Background","title":"Background","text":"Continuous ranked probability score (CRPS): Display CRPS. Dawid-Sebastiani score (DSS): Display DSS. Log score (LS): Display LS. Coverage: Display coverage. Bias: Display bias. Probability integral transform (PIT): Display PIT.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"probabilistic-metrics-1","dir":"Articles","previous_headings":"","what":"Background","title":"Background","text":"Mean absolute error (MAE): Display MAE. Root mean squared error (RMSE): Display RMSE. R-squared: Display R-squared. PIT Binned Density Plots: Select models PIT binned density plots shown.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"prediction-plots","dir":"Articles","previous_headings":"Predictive Analytics > Input","what":"Prediction Plots","title":"Background","text":"Models plot: Select models --sample predictions shown evaluation metrics calculated .","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"ensemble-bayesian-model-averaging","dir":"Articles","previous_headings":"Predictive Analytics > Input","what":"Ensemble Bayesian Model Averaging","title":"Background","text":"Ensemble Bayesian model averaging (eBMA) performs model averaging across --sample predictions several models. weights model estimated based predictive performance model computed slice. goal quantify uncertainty model selection improve predictive performance. weights previous slice used adjust predictions current slice - evaluation metrics calculated adjusted predictions. Expectation-Maximisation (EM): Uses expectation-maximization algorithm estimate weights model. default faster. Sets model weights zero Gibbs sampling. Gibbs: Performs Gibbs sampling estimate weights model. Slower produces full posterior distribution model. Sets fewer model weights zero EM. Next test slice: model weights computed whole slice used adjust predictions next slice predictive performance evaluated. Last xx percent data: Determines percentage slice performance eBMA method tested . example value 0.3 model weights computed first 70% slice used test prediction remaining 30% slice. Show per slice: Instead averaging weights across slices, show weights slice.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"future-prediction","dir":"Articles","previous_headings":"Predictive Analytics > Input","what":"Future Prediction","title":"Background","text":"section includes functionality predict future time series. number data points used train model future predictions default set training window used forecast evaluation. Also allows warning message via reporting mode indicated probability threshold crossing control bounds exceeded. Model Selection: Choose model used future predictions. Prediction horizon: Choose number time points predicted future. Last xx data points: Specify exact number. data points: Use data points available train prediction model. Spread points equally: Ignores timestamp data point plots sequentially distance . --bound probability threshold: Set probability threshold crossing control bounds triggers warning message. example, set 20% warning message triggered 20th quantile predictive distribution outside control bounds.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"advanced-options","dir":"Articles","previous_headings":"Predictive Analytics > Input","what":"Advanced Options","title":"Background","text":"Parrallel model computation: Select whether models computed parallel. can speed computation time can also produce errors windows. Skip training slices: Selects time points training window moved forward training window. default, set prediction window.","code":""},{"path":[]},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"basic-control-plot","dir":"Articles","previous_headings":"Predictive Analytics > Output > Time Series Descriptives","what":"Basic Control Plot","title":"Background","text":"Displays time stamps (time points) x-axis time series variable y-axis. control limits displayed dashed horizontal lines. control limits based settings control bounds. Data points outside control bounds displayed red points/lines, whereas data points within control bounds displayed blue points/lines.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"basic-control-plot---focused","dir":"Articles","previous_headings":"Predictive Analytics > Output > Time Series Descriptives","what":"Basic Control Plot - Focused","title":"Background","text":"basic control plot displays subset data indicated user.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"control-summary-table","dir":"Articles","previous_headings":"Predictive Analytics > Output > Diagnostics","what":"Control Summary Table","title":"Background","text":"Displays summary statistics time series divides depending whether data within outside control bounds. - Control Area: - : data points. - : Data points upper control limit. - : Data points lower control limit. - Inside: Data points within control bounds. - Mean: Mean data points. - SD: Standard deviation data points. - Minumum: Minimum value. - Maximum: Maximum value. - Valid: Number valid data points missing invalid. - Percent: Percentage valid data points fall category. - Average Deviation: Average distance corresponding control limit.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"outlier-table","dir":"Articles","previous_headings":"Predictive Analytics > Output > Diagnostics","what":"Outlier Table","title":"Background","text":"Table displays time stamp (time point) value data points outside control bounds. - Time: Time stamp (time point) data point. - Control Area: Whether data point control bounds. - Value: Value data point outside control bounds. - Deviation: Distance corresponding control limit.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"histogram","dir":"Articles","previous_headings":"Predictive Analytics > Output > Diagnostics","what":"Histogram","title":"Background","text":"Displays histogram counts y-axis values x-axis. Data points outside control bounds displayed red bars, whereas data points within control bounds displayed blue bars.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"autocorrelation-function-plot","dir":"Articles","previous_headings":"Predictive Analytics > Output > Diagnostics","what":"Autocorrelation Function Plot","title":"Background","text":"Displays strength autocorrelation y-axis lags x-axis dashed line indicates 95% confidence interval. higher autocorrelation, similar data points data points previous time point. autocorrelation plot used determine whether time series stationary .","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"partial-autocorrelation-plot","dir":"Articles","previous_headings":"Predictive Analytics > Output > Diagnostics","what":"Partial Autocorrelation Plot","title":"Background","text":"autocorrelation plot displays autocorrelation already explained autocorrelation smaller lag.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"forecast-evaluation-plan","dir":"Articles","previous_headings":"Predictive Analytics > Output > Forecast Evaluation","what":"Forecast Evaluation Plan","title":"Background","text":"Plot displays forecasting performance models evaluated. x-axis displays time points y-axis displays number data points used train model forecast evaluation. blue line indicates training window red line indicates prediction window. plot split different rows row represents single training slice.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"forecast-evaluation-metric-table","dir":"Articles","previous_headings":"Predictive Analytics > Output > Forecast Evaluation","what":"Forecast Evaluation Metric Table","title":"Background","text":"metrics averaged across slices based --sample prediction. metrics : - Model: Name model. - Continuous ranked probability score (CRPS): Compares predicted cumulative density function (CDF) actual CDF. Generalisation mean absolute error (MAE) whole predictive density. lower CRPS, better model. - Dawid-Sebastiani score (DSS): Compares predictive density actual CDF mean variance. lower DSS, better model. - Log score (LS): Compares predictive density actual CDF measuring logarithmic difference two. lower LS, better model. - Coverage: Proportion observations within 95% prediction interval. higher coverage, better model. - Bias: Indicates whether predictions systematically high low. bias -1 predictions smaller actual value. bias 1 predictions larger actual value. closer bias 0, unbiased model. - Probability Integral Transform (PIT): Evaluates calibration model treating test observation random variable coming predictive distribution. PIT value 0.5 model perfectly calibrated. PIT value 0 model overconfident PIT value 1 model underconfident. closer PIT value 0.5, better model.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"pit-density-density-plot","dir":"Articles","previous_headings":"Predictive Analytics > Output > Forecast Evaluation","what":"PIT Density Density Plot","title":"Background","text":"Plots PIT values model averaged across slices. x-axis displays PIT values y-axis displays density. model perfectly calibrated density uniform across PIT values density 0.1 bar.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"prediction-plot","dir":"Articles","previous_headings":"Predictive Analytics > Output > Forecast Evaluation","what":"Prediction Plot","title":"Background","text":"Displays actual observations predictions selected models. x-axis displays time points y-axis displays values time series variable. different models displayed different colors corresponding model names displayed legend.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"bma---model-weights","dir":"Articles","previous_headings":"Predictive Analytics > Output > Ensemble Bayesian Model Averaging","what":"BMA - Model Weights","title":"Background","text":"Displays model weights either averaged across slices slice seperately. - Model: Name model. - Weights: Corresponding toe model weight assigned eBMA. Higher weights indicates better predictive performance. Formally defined probability observations originated model.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/general_documentation.html","id":"future-prediction-plot","dir":"Articles","previous_headings":"Predictive Analytics > Output > Future Prediction","what":"Future Prediction Plot","title":"Background","text":"Plots predictions unobserved future. black dashed line indicates start prediction. blue area indicates 95% prediction interval. x-axis displays time points y-axis displays values time series variable. red dashed line present indicates time point control bounds exceeded depending probability threshold.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/getting_started.html","id":"process-control","dir":"Articles","previous_headings":"","what":"Process Control","title":"Getting Started","text":"process control usually process continuously generates data want monitor time make sure stays within desired boundaries time. example, health care setting might interested monitoring absenteeism rate employees order detect potential outbreak diseases (Woodall & Montgomery, 2014). industry context, might continuous production process interested monitoring dimension produced product ensure reliable enough sold. (citation). Univariate Predictive Analytics analysis offers several options determine control limits determine whether process --bound . control limits can either set manually based data selecting number standard deviations mean beyond data considered control. Alternatively, control limits can directly computed (subset) dataset investigated. Additionally includes basic quality control chart, process control summary statistics outlier tables. Multivariate Binomial Control currently","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/getting_started.html","id":"probabilistic-time-series-prediction","dir":"Articles","previous_headings":"","what":"Probabilistic Time Series Prediction","title":"Getting Started","text":"interested monitoring whether process currently control rather whether going control future can make use time series prediction. especially valuable production process multiple production steps: Detecting system produces faulty parts end production cycle increases loss parts current cycle might need discarded. Thus able predict whether process going go control can significantly save cost time enables act time. Thus Univariate Predictive Analytics analysis includes several time series prediction models trained historical data make predictions future. available models range classical time series models (e.g. state space models, prophet) flexible machine learning models (Bayesian additive regression trees). Additionally, put emphasis probabilistic forecasting method (Gneiting & Katzfuss, 2014) allows us quantify uncertainty estimates - predict process go control also probability.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/getting_started.html","id":"forecast-evaluation","dir":"Articles","previous_headings":"","what":"Forecast Evaluation","title":"Getting Started","text":"order make decisions based predictions need confidence accuracy. One common way evaluate forecast accuracy repeatidly subset available historical data training test data set. training set used train statistical model make predictions test set compared real observation. can compute various forecasting metrics quantify accuracy model help determining best model. Currently Univariate Predictive Analytics analysis offers forecasting evaluation. accuracy assessed forecast metrics based point predictions (R-squared mean absolute error) well probabilistic metrics take account whole predictive distribution (e.g. Logarithmic score Continuous Ranked Probability Score).","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/getting_started.html","id":"ensemble-bayesian-model-averaging","dir":"Articles","previous_headings":"","what":"Ensemble Bayesian Model Averaging","title":"Getting Started","text":"Instead relying single best model predict future, can also combine predictions different models. First, benefit takes account uncertainty model selection simply selecting single best model might produce overconfident results (Wagenmakers et al., 2022). Additionally, problem hand might complex represented well single model - combining different models might provide better predictuon model capture unique aspect problem hand (Sagi & Rokach, 2018). last point, reduces chances selecting wrong model user don’t manually pick one. Univariate Predictive Analytics analysis includes ensemble Bayesian model averaging method combine predictions different models(Raftery et al., 2005). model weighted according historical predictive accuracy (see previous section) predictions combined predict future. model weight can interpreted relative probability true model.","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/quality_control.html","id":"selecting-necessary-variables","dir":"Articles","previous_headings":"Determining the control bounds","what":"Selecting necessary variables","title":"Univariate Predictive Analytics - Simulated data set","text":"first step need load data JASP shown following image: different options mean? Dependent Variable y continuous production process want monitor predict time. Time variable time contains time stamps must supplied. Supplying Covariates Factors optional since necessary classical time series models rely time. case available can include improve predictive accuracy. use sensor readings beginning time series well temperature reading. Additionally, two variables called day_new_time_since day_new_n_since indicate many pieces produced since much time passed since start day. useful time machine directly related temperature. Lastly, Include Training variable indicates whether time point used training verifying model (set 1) whether used predict future make decisions. observations dependent variable course available data points want predict , needed supply covariates factors included build model.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/quality_control.html","id":"control-plot-and-control-limits","dir":"Articles","previous_headings":"Determining the control bounds","what":"Control plot and control limits","title":"Univariate Predictive Analytics - Simulated data set","text":"variables supplied, automatically get basic control plot result section JASP: red dashed lines indicate control bounds don’t want cross. default limit set way data 2 standard deviations away mean flagged --control. mere visual inspection alone can already see two things: seems pattern process abruptly starts high slowly declines towards middle. (wording). mentioned previously, directly relates effect temperature: Since measure process several days, machine cools night turned . lower temperature causes produced pieces larger. machine continuously, temperature rises certain degree size piece somewhat stable. second observation process seems go --control end time series quite rapidly. hypothetical explanation part machine broke inside machine subsequently heats machine much drastically explains process going --control. Since undesirable let process go--control, test tutorial whether can predict whether process goes --control! let us first adjust control limits. production processes often know large/small produced object must don’t set control bounds based data. example shift control limits bit last part time series clearly goes --control. can Time Series Descriptives section: Error Bound Selection option can select Manual Bounds manually input upper/lower limit 8.2/7.15 changes plot following: Now set control limits next step select .","code":""},{"path":[]},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/quality_control.html","id":"choosing-evaluation-plan","dir":"Articles","previous_headings":"Selection and validation of candidate models","what":"Choosing Evaluation plan","title":"Univariate Predictive Analytics - Simulated data set","text":"mentioned previously, want choose model predicts future best. One method cross validation exisiting data split training test data set. training set used train statistical model make predictions test set compared real observation. goal evaluate predictive performance unseen future observation, normal cross validation randomly selects training test data appropriate. Instead, data split way training data always temporally test data. example want train models amount past data use thenext 100 data points test data constitutes one production cycle. Afterwards shift training window ahead certain amount data points, retrain models predict next 100 data points. called rolling window cross validation historical historical forecast evaluation. settings procedure can found “Forecast Evaluation” section JASP (see image). evaluate whether can predict process goes --control last section. Training window option refers many past data points model trained . Since experience underlying shift last day process goes control, train models past 75 data points. practice might unknownon much data model trained different options considered. underlying data generating process stays constant time, models ideally trained past - can achieved checking option Cumulative Training. process changes time predictive performance deteriorates underlying process might warrant shorter training windows. Prediction window option determines many data points predicted future. ideally chosen way corresponds prediction horizon one interested predicting (different models might perform better short long-term forecasts). example corresponds prediction horizon 100 represents one full cycle. next option called Skip training slices indicates many data points shifted ahead prediction slice. Maximum nr. slices option determines many folds created. Increasing number leads less prediction slices folds computed might increase computation time. Especially computational time scarce since want make timely prediction future, might want select smaller number. case selected 6 want predict last part process data goes --control. check Show evaluation option can also see evaluation plan visualized check data model evaluate (see Figure 6). see blue colored data training period models trained whereas red period predicted compared actual observations.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/quality_control.html","id":"selecting-candidate-models","dir":"Articles","previous_headings":"Selection and validation of candidate models","what":"Selecting candidate models","title":"Univariate Predictive Analytics - Simulated data set","text":"Now plan evaluate data, can select models want use predict future. can find option selecting different models Forecast Evaluation section Model Choice. left side selection option, available models displayed right side indicates models chosen prediction. little explanation naming convention models: model family indicated first part model name hyphen “-” text afterwards indicates model specification. -depth explanation models resources see Background section. example selected models, prophet model Bayesian time series model automatically models appropriate seasonality via fourier orders, trend change points. time series model, predicts future observation dependent variable based past values. want add covariates, select prohpet - regression model. second model denoted bart - regression Bayesian Additive Regression Tree model. combines multiple decision trees large ensemble model able model high-dimensional non-linear relationships. time series default, need supply least covariates selection example. Additionally, also possible supply lagged dependent variable. enable option Feature Engineering section, internally new column created contains dependent variable previous time point. way even models time series models can model relationship variable time. model predicts future data points test set, predicted value time point t iteratively used input covariate prediction time point t+1. Note takes long time BART model model generally takes long time compute. selected models like use prediction, models trained evaluated based evaluation plan specified earlier. computations finished, get table corresponding evaluation metrics also able plot predictions.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/quality_control.html","id":"choosing-an-appropriate-evaluation-metrics","dir":"Articles","previous_headings":"Selection and validation of candidate models","what":"Choosing an appropriate evaluation metrics","title":"Univariate Predictive Analytics - Simulated data set","text":"One can evaluate prediction accuracy models computing called evaluation forecast metrics measure well models predict future comparing actual observations test set predictions. JASP module offers probabilistic point-based prediction metrics: Instead relying point mean prediction model, probabilistic forecast metrics compute much observed value differs whole predictive distribution. way able take account uncertainty associated predictive distribution. Ideally distribution sharp indicates certain prediction. current example focus mean absolute error (MAE), Continuous Ranked Probability Score (CRPS) R-squared value. name suggests MAE calculated calculating observations differs forecast absolute terms (.e. removing minus negative numbers) averaging across predicted observations. CRPS generalizes MAE computes whole predictive distribution instead single forecast observation. R-squared value hand computes much variance explained forecast. forecast metrics explained detail . Now let’s look table forecast evaluation metrics","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/articles/tutorials.html","id":"univariate-predictive-analytics","dir":"Articles","previous_headings":"","what":"Univariate Predictive Analytics","title":"Tutorials","text":"Simulated data set   Shows main capabilities module simulated manufacturing process influenced temperature machine, wear machine parts random error.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"JASP Team. Maintainer.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Team J (2023). jaspPredictiveAnalytics: Probalistic time series forecasting focus quality control predictions.. R package version 0.1.0, https://petersen-f.github.io/jaspPredictiveAnalytics/.","code":"@Manual{,   title = {jaspPredictiveAnalytics: Probalistic time series forecasting with a focus on quality control predictions.},   author = {JASP Team},   year = {2023},   note = {R package version 0.1.0},   url = {https://petersen-f.github.io/jaspPredictiveAnalytics/}, }"},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/index.html","id":"jasppredictiveanalytics-","dir":"","previous_headings":"","what":"Probalistic time series forecasting with a focus on quality control predictions. ","title":"Probalistic time series forecasting with a focus on quality control predictions. ","text":"Predictive Analytics module JASP adds extensive time series prediction methods JASP. combines classical time series methods machine learning models quality control concepts. Quality control techniques monitor whether certain process remains within predefined boundaries. way one can intervene boundaries crossed ensure product service desired quality. Time series forecasting allows us predict process develop future. way can predict ahead time whether process goes beyond boundaries ahead time. prediction models probabilistic, can predict process go control future also quantify uncertainty associated prediction.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting started","title":"Probalistic time series forecasting with a focus on quality control predictions. ","text":"get general overview package read Getting Started article. specific instructions use modules see tutorials. get -depth understanding functionality recommend reading background articles.","code":""},{"path":"https://petersen-f.github.io/jaspPredictiveAnalytics/index.html","id":"ressources","dir":"","previous_headings":"","what":"Ressources","title":"Probalistic time series forecasting with a focus on quality control predictions. ","text":"Read documentation (page) Open issue (Github issues report bugs request features) Ask question (Forum) Email maintainer","code":""}]
